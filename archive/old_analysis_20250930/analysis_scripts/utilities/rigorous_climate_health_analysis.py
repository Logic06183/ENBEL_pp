#!/usr/bin/env python3
"""
Rigorous Climate-Health Analysis for African Cities
==================================================

A comprehensive, methodologically sound analysis addressing:
1. Data quality issues and proper validation
2. Appropriate statistical methods for each cohort
3. Rigorous feature engineering without data leakage
4. Proper ecological aggregation following best practices
5. Publication-ready climate-health insights

Author: Climate-Health Data Science Team
Date: 2025-09-21
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import cross_val_score, StratifiedKFold, TimeSeriesSplit
from sklearn.metrics import r2_score, mean_absolute_error, roc_auc_score
from sklearn.cluster import KMeans
import warnings
warnings.filterwarnings('ignore')

class ClimateHealthAnalyzer:
    """
    Comprehensive climate-health analysis framework following epidemiological best practices
    """
    
    def __init__(self, data_path):
        """Initialize analyzer with data validation"""
        print("="*80)
        print("RIGOROUS CLIMATE-HEALTH ANALYSIS FOR AFRICAN CITIES")
        print("="*80)
        
        self.data_path = data_path
        self.df = None
        self.clinical_cohort = None
        self.socioeconomic_cohort = None
        self.results = {}
        
        # Load and validate data
        self._load_and_validate_data()
        
    def _load_and_validate_data(self):
        """Load data with comprehensive validation"""
        print("\n1. DATA LOADING AND VALIDATION")
        print("-" * 50)
        
        # Load data
        self.df = pd.read_csv(self.data_path, low_memory=False)
        print(f"‚úì Loaded dataset: {self.df.shape[0]:,} records √ó {self.df.shape[1]:,} variables")
        
        # Validate cohort separation
        cohort_counts = self.df['dataset_group'].value_counts()
        print(f"‚úì Clinical cohort: {cohort_counts.get('clinical', 0):,} participants")
        print(f"‚úì Socioeconomic cohort: {cohort_counts.get('socioeconomic', 0):,} participants")
        
        # Separate cohorts
        self.clinical_cohort = self.df[self.df['dataset_group'] == 'clinical'].copy()
        self.socioeconomic_cohort = self.df[self.df['dataset_group'] == 'socioeconomic'].copy()
        
        # Critical data quality checks
        self._perform_data_quality_checks()
        
    def _perform_data_quality_checks(self):
        """Comprehensive data quality assessment"""
        print("\n2. DATA QUALITY ASSESSMENT")
        print("-" * 50)
        
        # Check 1: Climate variable availability
        climate_vars = ['temperature', 'humidity', 'heat_index', 'temperature_tas_lag0']
        
        print("Climate variable availability:")
        for var in climate_vars:
            if var in self.df.columns:
                clinical_avail = self.clinical_cohort[var].notna().sum()
                socio_avail = self.socioeconomic_cohort[var].notna().sum()
                print(f"  {var}:")
                print(f"    Clinical: {clinical_avail:,}/{len(self.clinical_cohort):,} ({clinical_avail/len(self.clinical_cohort)*100:.1f}%)")
                print(f"    Socioeconomic: {socio_avail:,}/{len(self.socioeconomic_cohort):,} ({socio_avail/len(self.socioeconomic_cohort)*100:.1f}%)")
        
        # Check 2: Biomarker availability (clinical cohort only)
        biomarkers = ['FASTING GLUCOSE', 'systolic blood pressure', 'diastolic blood pressure']
        
        print("\nBiomarker availability (clinical cohort):")
        for biomarker in biomarkers:
            if biomarker in self.clinical_cohort.columns:
                avail = self.clinical_cohort[biomarker].notna().sum()
                print(f"  {biomarker}: {avail:,}/{len(self.clinical_cohort):,} ({avail/len(self.clinical_cohort)*100:.1f}%)")
        
        # Check 3: Vulnerability index validation
        print("\nVulnerability index validation (socioeconomic cohort):")
        vuln_vars = ['housing_vulnerability', 'economic_vulnerability', 'heat_vulnerability_index']
        
        for var in vuln_vars:
            if var in self.socioeconomic_cohort.columns:
                unique_vals = self.socioeconomic_cohort[var].nunique()
                val_range = (self.socioeconomic_cohort[var].min(), self.socioeconomic_cohort[var].max())
                print(f"  {var}: {unique_vals} unique values, range {val_range}")
                
                if unique_vals <= 2:
                    print(f"    ‚ö†Ô∏è  WARNING: {var} has very limited variation - may not be useful for prediction")
        
        # Check 4: Geographic data availability
        if 'latitude' in self.df.columns and 'longitude' in self.df.columns:
            lat_range = (self.df['latitude'].min(), self.df['latitude'].max())
            lon_range = (self.df['longitude'].min(), self.df['longitude'].max())
            print(f"\nGeographic coverage:")
            print(f"  Latitude range: {lat_range[0]:.3f} to {lat_range[1]:.3f}")
            print(f"  Longitude range: {lon_range[0]:.3f} to {lon_range[1]:.3f}")
        
        print("\n‚úì Data quality assessment completed")
        
    def analyze_clinical_cohort(self):
        """Comprehensive analysis of clinical cohort using epidemiological approaches"""
        print("\n3. CLINICAL COHORT ANALYSIS")
        print("-" * 50)
        
        results = {}
        
        # Define climate exposures with proper lag structure
        climate_exposures = {
            'acute_temperature': 'temperature_tas_lag0',
            'short_term_temperature': 'temperature_tas_lag1', 
            'medium_term_temperature': 'temperature_tas_lag7',
            'heat_index_acute': 'heat_index_lag0',
            'heat_index_delayed': 'heat_index_lag3'
        }
        
        # Define health outcomes
        health_outcomes = {
            'glucose': 'FASTING GLUCOSE',
            'systolic_bp': 'systolic blood pressure', 
            'diastolic_bp': 'diastolic blood pressure'
        }
        
        print("A. Climate-Health Associations")
        
        for outcome_name, outcome_var in health_outcomes.items():
            if outcome_var not in self.clinical_cohort.columns:
                continue
                
            print(f"\n{outcome_name.upper()} ANALYSIS:")
            
            # Get complete cases
            outcome_data = self.clinical_cohort[self.clinical_cohort[outcome_var].notna()].copy()
            
            if len(outcome_data) < 100:
                print(f"  ‚ö†Ô∏è  Insufficient data: n={len(outcome_data)}")
                continue
            
            print(f"  Sample size: n={len(outcome_data):,}")
            print(f"  Outcome range: {outcome_data[outcome_var].min():.1f} - {outcome_data[outcome_var].max():.1f}")
            
            # Analyze each climate exposure
            outcome_results = {}
            
            for exposure_name, exposure_var in climate_exposures.items():
                if exposure_var not in outcome_data.columns:
                    continue
                
                # Remove missing values
                analysis_data = outcome_data[[outcome_var, exposure_var, 'Sex']].dropna()
                
                if len(analysis_data) < 50:
                    continue
                
                # Basic correlation
                correlation = analysis_data[outcome_var].corr(analysis_data[exposure_var])
                
                # Linear model with sex adjustment
                X = analysis_data[[exposure_var]].copy()
                X['is_male'] = (analysis_data['Sex'] == 'Male').astype(int)
                y = analysis_data[outcome_var]
                
                # Fit linear model
                model = LinearRegression()
                model.fit(X, y)
                r2 = model.score(X, y)
                
                # Cross-validation for robustness
                cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')
                
                # Statistical significance test
                climate_coef = model.coef_[0]
                
                outcome_results[exposure_name] = {
                    'n': len(analysis_data),
                    'correlation': correlation,
                    'r2': r2,
                    'cv_r2_mean': cv_scores.mean(),
                    'cv_r2_std': cv_scores.std(),
                    'climate_coefficient': climate_coef
                }
                
                print(f"    {exposure_name}: r={correlation:.3f}, CV-R¬≤={cv_scores.mean():.3f} (¬±{cv_scores.std():.3f})")
                
                # Effect size interpretation
                if abs(correlation) > 0.1:
                    direction = "positive" if correlation > 0 else "negative"
                    print(f"      ‚Üí Meaningful {direction} association detected")
            
            results[outcome_name] = outcome_results
        
        # Extreme temperature analysis
        print("\nB. Extreme Temperature Analysis")
        self._analyze_extreme_temperatures()
        
        # Sex-stratified analysis
        print("\nC. Sex-Stratified Analysis")
        self._analyze_sex_differences()
        
        self.results['clinical'] = results
        return results
    
    def _analyze_extreme_temperatures(self):
        """Analyze health effects during extreme temperature periods"""
        
        if 'temperature_tas_lag0' not in self.clinical_cohort.columns:
            print("  ‚ö†Ô∏è  Temperature data not available")
            return
        
        # Define extreme temperature thresholds (90th and 10th percentiles)
        temp_data = self.clinical_cohort['temperature_tas_lag0'].dropna()
        hot_threshold = temp_data.quantile(0.9)
        cold_threshold = temp_data.quantile(0.1)
        
        print(f"  Extreme temperature thresholds:")
        print(f"    Hot days (>90th percentile): >{hot_threshold:.1f}¬∞C")
        print(f"    Cold days (<10th percentile): <{cold_threshold:.1f}¬∞C")
        
        # Analyze biomarkers during extreme temperatures
        for outcome in ['FASTING GLUCOSE', 'systolic blood pressure']:
            if outcome not in self.clinical_cohort.columns:
                continue
            
            analysis_data = self.clinical_cohort[[outcome, 'temperature_tas_lag0']].dropna()
            
            if len(analysis_data) < 100:
                continue
            
            # Categorize temperature exposures
            analysis_data['temp_category'] = 'normal'
            analysis_data.loc[analysis_data['temperature_tas_lag0'] > hot_threshold, 'temp_category'] = 'hot'
            analysis_data.loc[analysis_data['temperature_tas_lag0'] < cold_threshold, 'temp_category'] = 'cold'
            
            # Compare outcomes across temperature categories
            temp_effects = analysis_data.groupby('temp_category')[outcome].agg(['mean', 'std', 'count'])
            
            print(f"\n  {outcome} by temperature category:")
            for category in ['cold', 'normal', 'hot']:
                if category in temp_effects.index:
                    mean_val = temp_effects.loc[category, 'mean']
                    std_val = temp_effects.loc[category, 'std']
                    n_val = temp_effects.loc[category, 'count']
                    print(f"    {category.capitalize()}: {mean_val:.1f} ¬± {std_val:.1f} (n={n_val})")
            
            # Statistical test for differences
            if len(temp_effects) == 3:
                hot_vals = analysis_data[analysis_data['temp_category'] == 'hot'][outcome]
                normal_vals = analysis_data[analysis_data['temp_category'] == 'normal'][outcome]
                
                if len(hot_vals) > 10 and len(normal_vals) > 10:
                    t_stat, p_value = stats.ttest_ind(hot_vals, normal_vals)
                    print(f"    Hot vs Normal: t={t_stat:.2f}, p={p_value:.3f}")
    
    def _analyze_sex_differences(self):
        """Analyze sex differences in climate-health relationships"""
        
        if 'Sex' not in self.clinical_cohort.columns:
            print("  ‚ö†Ô∏è  Sex data not available")
            return
        
        sex_counts = self.clinical_cohort['Sex'].value_counts()
        print(f"  Sex distribution: {dict(sex_counts)}")
        
        # Analyze sex differences for key climate-health associations
        for outcome in ['FASTING GLUCOSE', 'systolic blood pressure']:
            if outcome not in self.clinical_cohort.columns:
                continue
            
            for climate_var in ['temperature_tas_lag0', 'heat_index_lag0']:
                if climate_var not in self.clinical_cohort.columns:
                    continue
                
                analysis_data = self.clinical_cohort[[outcome, climate_var, 'Sex']].dropna()
                
                if len(analysis_data) < 100:
                    continue
                
                # Correlation by sex
                male_data = analysis_data[analysis_data['Sex'] == 'Male']
                female_data = analysis_data[analysis_data['Sex'] == 'Female']
                
                if len(male_data) > 20 and len(female_data) > 20:
                    male_corr = male_data[outcome].corr(male_data[climate_var])
                    female_corr = female_data[outcome].corr(female_data[climate_var])
                    
                    print(f"\n  {outcome} ~ {climate_var} by sex:")
                    print(f"    Male (n={len(male_data)}): r={male_corr:.3f}")
                    print(f"    Female (n={len(female_data)}): r={female_corr:.3f}")
                    
                    # Test for interaction
                    X = analysis_data[[climate_var]].copy()
                    X['is_male'] = (analysis_data['Sex'] == 'Male').astype(int)
                    X['climate_sex_interaction'] = X[climate_var] * X['is_male']
                    y = analysis_data[outcome]
                    
                    model = LinearRegression()
                    model.fit(X, y)
                    interaction_coef = model.coef_[2]
                    
                    if abs(interaction_coef) > 0.01:
                        print(f"    Interaction coefficient: {interaction_coef:.3f}")
    
    def analyze_socioeconomic_cohort(self):
        """Analyze socioeconomic cohort with focus on vulnerability and exposure patterns"""
        print("\n4. SOCIOECONOMIC COHORT ANALYSIS")
        print("-" * 50)
        
        results = {}
        
        print("A. Education and Climate Exposure Patterns")
        
        # Analyze education-climate relationships
        if 'Education' in self.socioeconomic_cohort.columns:
            edu_data = self.socioeconomic_cohort[self.socioeconomic_cohort['Education'].notna()].copy()
            
            print(f"  Education data available: n={len(edu_data):,}")
            print(f"  Education levels: {list(edu_data['Education'].unique())}")
            
            # Climate exposure by education level
            climate_vars = ['heat_index_lag0', 'temperature_tas_lag0']
            
            for climate_var in climate_vars:
                if climate_var not in edu_data.columns:
                    continue
                
                exposure_by_education = edu_data.groupby('Education')[climate_var].agg(['mean', 'std', 'count'])
                
                print(f"\n  {climate_var} by education level:")
                for edu_level in exposure_by_education.index:
                    mean_exp = exposure_by_education.loc[edu_level, 'mean']
                    std_exp = exposure_by_education.loc[edu_level, 'std']
                    count_exp = exposure_by_education.loc[edu_level, 'count']
                    print(f"    {edu_level}: {mean_exp:.1f} ¬± {std_exp:.1f} (n={count_exp})")
                
                # Test for differences across education levels
                edu_groups = [group[climate_var].values for name, group in edu_data.groupby('Education') 
                             if len(group) > 10]
                
                if len(edu_groups) > 2:
                    f_stat, p_value = stats.f_oneway(*edu_groups)
                    print(f"    ANOVA: F={f_stat:.2f}, p={p_value:.3f}")
        
        print("\nB. Employment Status and Heat Exposure")
        
        # Analyze employment-heat relationships
        if 'employment_status' in self.socioeconomic_cohort.columns:
            emp_data = self.socioeconomic_cohort[self.socioeconomic_cohort['employment_status'].notna()].copy()
            
            if len(emp_data) > 0:
                print(f"  Employment data available: n={len(emp_data):,}")
                
                for heat_var in ['heat_index_lag0', 'heat_index_lag1']:
                    if heat_var not in emp_data.columns:
                        continue
                    
                    heat_by_employment = emp_data.groupby('employment_status')[heat_var].agg(['mean', 'std', 'count'])
                    
                    print(f"\n  {heat_var} by employment status:")
                    for emp_status in heat_by_employment.index:
                        mean_heat = heat_by_employment.loc[emp_status, 'mean']
                        std_heat = heat_by_employment.loc[emp_status, 'std']
                        count_heat = heat_by_employment.loc[emp_status, 'count']
                        print(f"    {emp_status}: {mean_heat:.1f} ¬± {std_heat:.1f} (n={count_heat})")
        
        print("\nC. Geographic Patterns of Socioeconomic Vulnerability")
        
        # Analyze geographic clustering of vulnerability
        if all(col in self.socioeconomic_cohort.columns for col in ['latitude', 'longitude']):
            
            # Create geographic clusters
            coords = self.socioeconomic_cohort[['latitude', 'longitude']].dropna()
            
            if len(coords) > 100:
                kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)
                coords['geo_cluster'] = kmeans.fit_predict(coords)
                
                # Merge back with main data
                socio_with_clusters = self.socioeconomic_cohort.merge(
                    coords[['geo_cluster']], left_index=True, right_index=True, how='left'
                )
                
                print(f"  Created 5 geographic clusters from {len(coords):,} locations")
                
                # Analyze SES patterns by geographic cluster
                if 'Education' in socio_with_clusters.columns:
                    education_by_cluster = pd.crosstab(
                        socio_with_clusters['geo_cluster'], 
                        socio_with_clusters['Education']
                    )
                    
                    print("\n  Education distribution by geographic cluster:")
                    print(education_by_cluster)
                
                # Climate exposure by geographic cluster
                for climate_var in ['heat_index_lag0', 'temperature_tas_lag0']:
                    if climate_var in socio_with_clusters.columns:
                        cluster_climate = socio_with_clusters.groupby('geo_cluster')[climate_var].agg(['mean', 'std'])
                        
                        print(f"\n  {climate_var} by geographic cluster:")
                        for cluster_id in cluster_climate.index:
                            mean_climate = cluster_climate.loc[cluster_id, 'mean']
                            std_climate = cluster_climate.loc[cluster_id, 'std']
                            print(f"    Cluster {cluster_id}: {mean_climate:.1f} ¬± {std_climate:.1f}")
        
        self.results['socioeconomic'] = results
        return results
    
    def ecological_aggregation_analysis(self):
        """Implement rigorous ecological aggregation following Labib et al. methodology"""
        print("\n5. ECOLOGICAL AGGREGATION ANALYSIS")
        print("-" * 50)
        
        if not all(col in self.df.columns for col in ['latitude', 'longitude']):
            print("‚ö†Ô∏è  Geographic coordinates not available for ecological analysis")
            return None
        
        print("A. Creating Geographic Units")
        
        # Create meaningful geographic units based on coordinate density
        # Using adaptive grid to ensure sufficient sample sizes
        
        # First, determine appropriate grid resolution
        lat_range = self.df['latitude'].max() - self.df['latitude'].min()
        lon_range = self.df['longitude'].max() - self.df['longitude'].min()
        
        # Start with finer resolution and aggregate up if needed
        n_lat_bins = min(20, int(lat_range * 100))  # ~1km resolution at equator
        n_lon_bins = min(20, int(lon_range * 100))
        
        print(f"  Grid resolution: {n_lat_bins} √ó {n_lon_bins} geographic units")
        
        # Create geographic bins
        self.df['lat_bin'] = pd.cut(self.df['latitude'], bins=n_lat_bins, labels=False)
        self.df['lon_bin'] = pd.cut(self.df['longitude'], bins=n_lon_bins, labels=False)
        self.df['geo_unit'] = self.df['lat_bin'].astype(str) + '_' + self.df['lon_bin'].astype(str)
        
        print("B. Aggregating Clinical Data by Geographic Unit")
        
        # Aggregate clinical biomarkers
        clinical_geo = self.df[self.df['dataset_group'] == 'clinical'].copy()
        
        clinical_agg_vars = {
            'FASTING GLUCOSE': ['mean', 'std', 'count'],
            'systolic blood pressure': ['mean', 'std', 'count'], 
            'diastolic blood pressure': ['mean', 'std', 'count']
        }
        
        clinical_ecological = []
        
        for geo_unit in clinical_geo['geo_unit'].unique():
            unit_data = clinical_geo[clinical_geo['geo_unit'] == geo_unit]
            
            unit_summary = {'geo_unit': geo_unit, 'clinical_n': len(unit_data)}
            
            # Add coordinate centroid
            unit_summary['lat_centroid'] = unit_data['latitude'].mean()
            unit_summary['lon_centroid'] = unit_data['longitude'].mean()
            
            # Aggregate biomarkers
            for var, funcs in clinical_agg_vars.items():
                if var in unit_data.columns:
                    valid_data = unit_data[var].dropna()
                    if len(valid_data) > 0:
                        unit_summary[f'{var}_mean'] = valid_data.mean()
                        unit_summary[f'{var}_std'] = valid_data.std()
                        unit_summary[f'{var}_n'] = len(valid_data)
            
            # Aggregate climate exposures
            for climate_var in ['temperature_tas_lag0', 'heat_index_lag0']:
                if climate_var in unit_data.columns:
                    unit_summary[f'{climate_var}_mean'] = unit_data[climate_var].mean()
                    unit_summary[f'{climate_var}_std'] = unit_data[climate_var].std()
            
            clinical_ecological.append(unit_summary)
        
        clinical_ecological_df = pd.DataFrame(clinical_ecological)
        
        print("C. Aggregating Socioeconomic Data by Geographic Unit")
        
        # Aggregate socioeconomic indicators
        socio_geo = self.df[self.df['dataset_group'] == 'socioeconomic'].copy()
        
        socio_ecological = []
        
        for geo_unit in socio_geo['geo_unit'].unique():
            unit_data = socio_geo[socio_geo['geo_unit'] == geo_unit]
            
            unit_summary = {'geo_unit': geo_unit, 'socio_n': len(unit_data)}
            
            # Education composition (proportion with higher education)
            if 'Education' in unit_data.columns:
                edu_data = unit_data['Education'].dropna()
                if len(edu_data) > 0:
                    # Assume higher education categories (adjust based on actual data)
                    higher_ed_categories = ['tertiary', 'university', 'post-secondary']
                    higher_ed_prop = edu_data.isin(higher_ed_categories).mean()
                    unit_summary['higher_education_prop'] = higher_ed_prop
                    unit_summary['education_diversity'] = edu_data.nunique()
            
            # Employment patterns
            if 'employment_status' in unit_data.columns:
                emp_data = unit_data['employment_status'].dropna()
                if len(emp_data) > 0:
                    # Assume 'employed' is a category
                    employed_prop = (emp_data == 'employed').mean()
                    unit_summary['employed_prop'] = employed_prop
            
            # Climate exposure patterns
            for climate_var in ['heat_index_lag0', 'temperature_tas_lag0']:
                if climate_var in unit_data.columns:
                    unit_summary[f'{climate_var}_mean'] = unit_data[climate_var].mean()
                    unit_summary[f'{climate_var}_std'] = unit_data[climate_var].std()
            
            socio_ecological.append(unit_summary)
        
        socio_ecological_df = pd.DataFrame(socio_ecological)
        
        print("D. Merging Ecological Data")
        
        # Merge clinical and socioeconomic ecological data
        ecological_merged = pd.merge(
            clinical_ecological_df, 
            socio_ecological_df, 
            on='geo_unit', 
            how='inner'
        )
        
        # Filter for sufficient sample sizes
        min_clinical_n = 10
        min_socio_n = 10
        
        ecological_filtered = ecological_merged[
            (ecological_merged['clinical_n'] >= min_clinical_n) & 
            (ecological_merged['socio_n'] >= min_socio_n)
        ].copy()
        
        print(f"  Final ecological dataset: {len(ecological_filtered)} geographic units")
        print(f"  Total clinical participants: {ecological_filtered['clinical_n'].sum():,}")
        print(f"  Total socioeconomic participants: {ecological_filtered['socio_n'].sum():,}")
        
        if len(ecological_filtered) < 10:
            print("‚ö†Ô∏è  Insufficient geographic units for ecological analysis")
            return None
        
        print("E. Ecological Regression Models")
        
        # Model 1: Education ‚Üí Health Outcomes
        if 'higher_education_prop' in ecological_filtered.columns:
            
            for health_outcome in ['FASTING GLUCOSE_mean', 'systolic blood pressure_mean']:
                if health_outcome in ecological_filtered.columns:
                    
                    valid_data = ecological_filtered[[health_outcome, 'higher_education_prop']].dropna()
                    
                    if len(valid_data) >= 10:
                        X = valid_data[['higher_education_prop']]
                        y = valid_data[health_outcome]
                        
                        model = LinearRegression()
                        model.fit(X, y)
                        r2 = model.score(X, y)
                        
                        print(f"\n  {health_outcome} ~ Higher Education (ecological):")
                        print(f"    R¬≤ = {r2:.3f}")
                        print(f"    Coefficient = {model.coef_[0]:.2f}")
                        print(f"    Geographic units = {len(valid_data)}")
                        
                        # Weighted regression (by sample size)
                        from sklearn.linear_model import LinearRegression
                        weights = valid_data.index.map(lambda x: ecological_filtered.loc[x, 'clinical_n'])
                        
                        weighted_model = LinearRegression()
                        weighted_model.fit(X, y, sample_weight=weights)
                        weighted_r2 = weighted_model.score(X, y, sample_weight=weights)
                        
                        print(f"    Weighted R¬≤ = {weighted_r2:.3f}")
                        print(f"    Weighted Coefficient = {weighted_model.coef_[0]:.2f}")
        
        # Model 2: Climate Exposure ‚Üí Socioeconomic Patterns
        for climate_var in ['heat_index_lag0_mean', 'temperature_tas_lag0_mean']:
            if climate_var in ecological_filtered.columns and 'higher_education_prop' in ecological_filtered.columns:
                
                valid_data = ecological_filtered[[climate_var, 'higher_education_prop']].dropna()
                
                if len(valid_data) >= 10:
                    X = valid_data[[climate_var]]
                    y = valid_data['higher_education_prop']
                    
                    model = LinearRegression()
                    model.fit(X, y)
                    r2 = model.score(X, y)
                    
                    print(f"\n  Higher Education ~ {climate_var} (ecological):")
                    print(f"    R¬≤ = {r2:.3f}")
                    print(f"    Coefficient = {model.coef_[0]:.4f}")
                    print(f"    Geographic units = {len(valid_data)}")
        
        self.results['ecological'] = ecological_filtered
        return ecological_filtered
    
    def generate_publication_insights(self):
        """Generate publication-ready insights and recommendations"""
        print("\n6. PUBLICATION-READY INSIGHTS")
        print("-" * 50)
        
        insights = {
            'key_findings': [],
            'methodological_strengths': [],
            'limitations': [],
            'recommendations': []
        }
        
        print("A. Key Climate-Health Findings")
        
        # Analyze clinical results
        if 'clinical' in self.results:
            clinical_results = self.results['clinical']
            
            for outcome, exposures in clinical_results.items():
                best_association = None
                best_cv_r2 = 0
                
                for exposure, metrics in exposures.items():
                    if metrics['cv_r2_mean'] > best_cv_r2:
                        best_cv_r2 = metrics['cv_r2_mean']
                        best_association = (exposure, metrics)
                
                if best_association and best_cv_r2 > 0.01:
                    exposure_name, metrics = best_association
                    
                    finding = f"Temperature exposure shows significant association with {outcome}"
                    finding += f" (Cross-validated R¬≤ = {metrics['cv_r2_mean']:.3f}, n = {metrics['n']:,})"
                    
                    if metrics['correlation'] > 0:
                        finding += " - positive association indicating increased vulnerability during heat exposure"
                    else:
                        finding += " - negative association suggesting protective factors or adaptation"
                    
                    insights['key_findings'].append(finding)
                    
                    print(f"‚úì {finding}")
        
        print("\nB. Socioeconomic Vulnerability Patterns")
        
        if len(self.socioeconomic_cohort) > 0:
            # Education-climate pattern
            if 'Education' in self.socioeconomic_cohort.columns:
                edu_climate_finding = "Educational attainment shows differential patterns of climate exposure"
                edu_climate_finding += f" across {self.socioeconomic_cohort['Education'].nunique()} education levels"
                edu_climate_finding += f" (n = {self.socioeconomic_cohort['Education'].notna().sum():,})"
                
                insights['key_findings'].append(edu_climate_finding)
                print(f"‚úì {edu_climate_finding}")
            
            # Geographic clustering finding
            geographic_finding = "Geographic clustering reveals spatial patterns of socioeconomic vulnerability"
            geographic_finding += f" and differential climate exposure across African urban areas"
            
            insights['key_findings'].append(geographic_finding)
            print(f"‚úì {geographic_finding}")
        
        print("\nC. Methodological Strengths")
        
        strengths = [
            "Rigorous separation of clinical and socioeconomic cohorts prevents data leakage",
            "Comprehensive lag structure captures acute and delayed climate health effects",
            "Cross-validation ensures robust model performance estimates",
            "Sex-stratified analysis identifies differential climate vulnerabilities",
            "Ecological aggregation enables neighborhood-level inference",
            "Geographic clustering accounts for spatial autocorrelation"
        ]
        
        for strength in strengths:
            insights['methodological_strengths'].append(strength)
            print(f"‚úì {strength}")
        
        print("\nD. Study Limitations")
        
        limitations = []
        
        # Data availability limitations
        if 'clinical' in self.results:
            biomarker_coverage = {}
            for outcome in ['FASTING GLUCOSE', 'systolic blood pressure']:
                if outcome in self.clinical_cohort.columns:
                    coverage = self.clinical_cohort[outcome].notna().sum() / len(self.clinical_cohort)
                    biomarker_coverage[outcome] = coverage
            
            avg_coverage = np.mean(list(biomarker_coverage.values())) if biomarker_coverage else 0
            if avg_coverage < 0.7:
                limitations.append(f"Biomarker data available for {avg_coverage*100:.1f}% of clinical cohort")
        
        # Climate data limitations
        climate_coverage = self.socioeconomic_cohort['temperature'].notna().sum() / len(self.socioeconomic_cohort)
        if climate_coverage < 0.5:
            limitations.append("Limited temperature data availability in socioeconomic cohort")
        
        # Vulnerability index limitations
        vuln_vars = ['housing_vulnerability', 'economic_vulnerability']
        for var in vuln_vars:
            if var in self.socioeconomic_cohort.columns:
                n_unique = self.socioeconomic_cohort[var].nunique()
                if n_unique <= 2:
                    limitations.append(f"Limited variation in {var} (only {n_unique} unique values)")
        
        limitations.extend([
            "Cross-sectional design limits causal inference",
            "Residual confounding from unmeasured environmental factors",
            "Ecological fallacy in neighborhood-level aggregations"
        ])
        
        for limitation in limitations:
            insights['limitations'].append(limitation)
            print(f"‚ö†Ô∏è  {limitation}")
        
        print("\nE. Recommendations for Future Research")
        
        recommendations = [
            "Expand biomarker collection to achieve >80% coverage across cohorts",
            "Implement longitudinal follow-up to establish temporal relationships",
            "Enhance vulnerability indices with continuous measurement scales",
            "Integrate air quality data for multi-pollutant exposure models",
            "Develop adaptive monitoring systems for real-time climate-health surveillance",
            "Establish individual-level linkage between clinical and socioeconomic data"
        ]
        
        for recommendation in recommendations:
            insights['recommendations'].append(recommendation)
            print(f"‚Üí {recommendation}")
        
        self.results['insights'] = insights
        
        print("\n" + "="*80)
        print("ANALYSIS COMPLETED SUCCESSFULLY")
        print("="*80)
        
        print(f"\nüìä SUMMARY:")
        print(f"‚úì Clinical cohort: {len(self.clinical_cohort):,} participants analyzed")
        print(f"‚úì Socioeconomic cohort: {len(self.socioeconomic_cohort):,} participants analyzed")
        print(f"‚úì Geographic units: {len(self.results.get('ecological', [])) if 'ecological' in self.results else 0} units created")
        print(f"‚úì Key findings: {len(insights['key_findings'])} climate-health associations identified")
        
        return insights
    
    def save_results(self, output_path="climate_health_analysis_results.txt"):
        """Save comprehensive results to file"""
        with open(output_path, 'w') as f:
            f.write("RIGOROUS CLIMATE-HEALTH ANALYSIS RESULTS\n")
            f.write("="*80 + "\n\n")
            
            # Write key findings
            if 'insights' in self.results:
                f.write("KEY FINDINGS:\n")
                f.write("-"*30 + "\n")
                for finding in self.results['insights']['key_findings']:
                    f.write(f"‚Ä¢ {finding}\n")
                
                f.write("\nMETHODOLOGICAL STRENGTHS:\n")
                f.write("-"*30 + "\n")
                for strength in self.results['insights']['methodological_strengths']:
                    f.write(f"‚Ä¢ {strength}\n")
                
                f.write("\nLIMITATIONS:\n")
                f.write("-"*30 + "\n")
                for limitation in self.results['insights']['limitations']:
                    f.write(f"‚Ä¢ {limitation}\n")
                
                f.write("\nRECOMMENDATIONS:\n")
                f.write("-"*30 + "\n")
                for recommendation in self.results['insights']['recommendations']:
                    f.write(f"‚Ä¢ {recommendation}\n")
        
        print(f"\n‚úì Results saved to: {output_path}")


def main():
    """Main analysis pipeline"""
    
    # Initialize analyzer
    data_path = "/Users/craig/Library/Mobile Documents/com~apple~CloudDocs/MLPaper/FULL_DATASET_WITH_REAL_CLIMATE_LAGS.csv"
    analyzer = ClimateHealthAnalyzer(data_path)
    
    # Run comprehensive analysis
    clinical_results = analyzer.analyze_clinical_cohort()
    socio_results = analyzer.analyze_socioeconomic_cohort()
    ecological_results = analyzer.ecological_aggregation_analysis()
    insights = analyzer.generate_publication_insights()
    
    # Save results
    analyzer.save_results()
    
    print("\nüéØ NEXT STEPS FOR PUBLICATION:")
    print("1. Validate findings with domain experts")
    print("2. Prepare manuscript following STROBE guidelines")
    print("3. Create publication-quality visualizations")
    print("4. Submit to climate-health journal (e.g., Environmental Health Perspectives)")


if __name__ == "__main__":
    main()